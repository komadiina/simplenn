{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEG3HdQiRG5O"
      },
      "outputs": [],
      "source": [
        "import torch as T\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import numpy as np\n",
        "\n",
        "from NeuralNet import NeuralNet\n",
        "from utils import *\n",
        "\n",
        "from sklearn.datasets import fetch_covtype\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNet(nn.Module):\n",
        "    def __init__(self, layers=[], loss_fn=None, device='cpu'):\n",
        "        super(NeuralNet, self).__init__()\n",
        "\n",
        "        # Prebacimo otpakovanu listu slojeva u nn.Sequential\n",
        "        self.layers: nn.Sequential = nn.Sequential(*layers)\n",
        "\n",
        "        # Definisimo funkciju gubitka za nas model\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "        # Definisimo uredjaj na kojem treniramo model\n",
        "        self.device = device\n",
        "        self.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Proslijedimo ulaz kroz sve slojeve\n",
        "        return self.layers(x)\n",
        "\n",
        "    def train_model(self, x, y, optimizer, epochs=1000, early_stopping=True, early_stopping_epochs=3,  verbose=False):\n",
        "        self.train()  # Treniranje modela\n",
        "\n",
        "        epoch_loss_increase = 0\n",
        "        previous_epoch_loss = 0\n",
        "        minimum_loss = 0\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            if verbose:\n",
        "                print(f'Epoch {epoch+1}/{epochs}')\n",
        "\n",
        "            x = x.to(self.device)\n",
        "            y = y.to(self.device)\n",
        "\n",
        "            # Proslijedimo ulaz kroz sve slojeve\n",
        "            y_pred = self.layers(x)\n",
        "\n",
        "            # Izracunajmo gubitak i propagirajmo unazad\n",
        "            loss = self.loss_fn(y_pred, y)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            if verbose:\n",
        "                print(f'Loss: {loss.item()}')\n",
        "\n",
        "            # Provjerimo da li je greska porasla iznad kriterijuma\n",
        "            if early_stopping:\n",
        "                if loss.item() > previous_epoch_loss:\n",
        "                    epoch_loss_increase += 1\n",
        "\n",
        "                    if epoch_loss_increase == early_stopping_epochs:\n",
        "                        print('Early stopping...')\n",
        "                        break\n",
        "                elif loss.item() < previous_epoch_loss:\n",
        "                    minimum_loss = loss.item()\n",
        "                    if verbose:\n",
        "                        print(\n",
        "                            f'---! NEW BEST EPOCH: !---\\nCurrent: {minimum_loss}\\nPrevious: {previous_epoch_loss}\\n---! NEW BEST EPOCH: !---\\n')\n",
        "                    epoch_loss_increase = 0\n",
        "                else:\n",
        "                    epoch_loss_increase = 0\n",
        "\n",
        "            # Sacuvajmo trenutnu vrijednost gubitka za sledeci pass\n",
        "            previous_epoch_loss = loss.item()\n",
        "\n",
        "        # Vratimo 'najbolji' rezultat minibatch-a\n",
        "        return minimum_loss\n",
        "\n",
        "    def test_model(self, x, y, verbose=True):\n",
        "        self.eval()  # Testiranje modela\n",
        "\n",
        "        total_loss = 0\n",
        "\n",
        "        predictions = np.array([])\n",
        "\n",
        "        with T.no_grad():\n",
        "            for i in range(len(x)):\n",
        "                if verbose:\n",
        "                    print(f'Running test example [{i+1}/{len(x)}]')\n",
        "\n",
        "                x = x.to(self.device)\n",
        "                y = y.to(self.device)\n",
        "\n",
        "                # Proslijedimo ulaz kroz sve slojeve\n",
        "                y_pred = self.layers(x)\n",
        "                predictions = np.append(predictions, y_pred)\n",
        "\n",
        "                loss = self.loss_fn(y_pred, y)\n",
        "                total_loss += loss.item()\n",
        "\n",
        "                if verbose:\n",
        "                    print(\n",
        "                        f'[TEST_{i}] current loss: {loss.item()}, total_loss = {total_loss}')\n",
        "\n",
        "        if verbose:\n",
        "            print(f'Average loss: {total_loss/len(x)}')\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def predict(self, x):\n",
        "        # Upitno ali ajde\n",
        "        self.eval()  # Testiranje modela\n",
        "\n",
        "        # Proslijedimo ulaz kroz sve slojeve\n",
        "        return self.layers(x)\n"
      ],
      "metadata": {
        "id": "pxr17AfLRHn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWND7aPMRG5R"
      },
      "outputs": [],
      "source": [
        "X, y = fetch_covtype(return_X_y=True)\n",
        "y = y.reshape((-1, 1))\n",
        "\n",
        "X = StandardScaler().fit_transform(X)\n",
        "y = StandardScaler().fit_transform(y)\n",
        "y = y.reshape(-1)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True)\n",
        "X_train, X_test, y_train, y_test = to_tensor(X_train), to_tensor(\n",
        "    X_test), to_tensor(y_train, dtype=T.long), to_tensor(y_test, dtype=T.long)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfqhUaUGRG5R",
        "outputId": "47b0e277-37c3-43b3-d55f-208e1c6e986d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([464809, 54]) torch.Size([464809]) torch.Size([116203, 54]) torch.Size([116203])\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1PIpbQwRG5T"
      },
      "outputs": [],
      "source": [
        "train = TensorDataset(X_train, y_train)\n",
        "test = TensorDataset(X_test, y_test)\n",
        "\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test, batch_size=batch_size, shuffle=True)\n",
        "device = T.device(\"cuda:0\") if T.cuda.is_available() else T.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HnBpQvHORG5T"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss(reduction='mean')\n",
        "\n",
        "nets = [\n",
        "    NeuralNet(layers=[\n",
        "      nn.Linear(54, 128),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.1),\n",
        "\n",
        "      nn.Linear(128, 128),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.1),\n",
        "\n",
        "      nn.Linear(128, 64),\n",
        "      nn.GELU(),\n",
        "\n",
        "      nn.Linear(64, 7),\n",
        "      nn.LogSoftmax(dim=1),\n",
        "  ], loss_fn=loss_fn, device=device),\n",
        "    NeuralNet(layers=[\n",
        "      nn.Linear(54, 128),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.2),\n",
        "\n",
        "      nn.Linear(128, 256),\n",
        "      nn.ReLU(),\n",
        "      nn.Dropout(0.1),\n",
        "\n",
        "      nn.Linear(256, 7),\n",
        "      nn.LogSoftmax(dim=1)\n",
        "  ], loss_fn=loss_fn, device=device)]\n",
        "\n",
        "lr = 1e-3\n",
        "weight_decay = 1e-5\n",
        "\n",
        "optim = T.optim.Adam(net.parameters(), lr=lr, weight_decay=weight_decay)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eUSgi_dpRG5U"
      },
      "outputs": [],
      "source": [
        "num_epochs = 35\n",
        "early_stopping_epochs = 3\n",
        "\n",
        "batch = 0\n",
        "for x, y in train_loader:\n",
        "    print(f'Batch: {batch}')\n",
        "    net.train_model(x, y, optim, num_epochs, early_stopping_epochs, verbose=True)\n",
        "    batch += batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9F8PYcaRG5U"
      },
      "outputs": [],
      "source": [
        "for x, y in test_loader:\n",
        "    net.test_model(x, y, verbose=True)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}